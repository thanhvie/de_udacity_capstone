{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "The purpose of this project is to create an data modeling for US immigration by creating ETL pipeline for I94 immigration, global land temperatures and US demographics datasets. With this data modeling (analytics database), data analysts can further deep dive into to find out insights which will helps to understand underlying patterns of US immigration. \n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In this project, I will use Apache Spark to do data analysis which include below actions:\n",
    "- Data preprocessing and exploring for I94 immigration dataset\n",
    "- Data preprocessing and exploring for us-cities-demographic dataset\n",
    "- Data preprocessing and exploring for global temperature dataset\n",
    "- Create dimension tables\n",
    "- Create fact table\n",
    "\n",
    "#### Describe and Gather Data \n",
    "There will be 3 datasets using in this project.\n",
    "- **I94 Immigration Data**: This data comes from the US National Tourism and Trade Office which non-U.S, citizens from overseas countries and Mexico (traveling by air and sea) must complete an I-94 form to enter the United States. These forms are recorded into I94 Immigration dataset.\n",
    "You can access the immigration data in a folder with the following path: `../../data/18-83510-I94-Data-2016/`.\n",
    "- **World Temperature Data**: This dataset came from Kaggle. You can read more about this [here](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "You can access the temperature data in a folder with the following path: `../../data2/`. There's just one file in that folder, called `GlobalLandTemperaturesByCity.csv`\n",
    "- **U.S. City Demographic Data**: This data comes from OpenSoft. You can read more about it [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "### Import Spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import isnan, when, count, col, udf, dayofmonth, dayofweek, month, year, weekofyear\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### I94 Immigration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i94_apr16_sub.sas7bdat',\n",
       " 'i94_sep16_sub.sas7bdat',\n",
       " 'i94_nov16_sub.sas7bdat',\n",
       " 'i94_mar16_sub.sas7bdat',\n",
       " 'i94_jun16_sub.sas7bdat',\n",
       " 'i94_aug16_sub.sas7bdat',\n",
       " 'i94_may16_sub.sas7bdat',\n",
       " 'i94_jan16_sub.sas7bdat',\n",
       " 'i94_oct16_sub.sas7bdat',\n",
       " 'i94_jul16_sub.sas7bdat',\n",
       " 'i94_feb16_sub.sas7bdat',\n",
       " 'i94_dec16_sub.sas7bdat']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list all files in the customer repository\n",
    "files = os.listdir('../../data/18-83510-I94-Data-2016/')\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "There is many files in `118-83510-I94-Data-2016`, in this project template we will do data analysis for one file. The analysis flow is the same for other files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_df = spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first five records\n",
    "immigration_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of row of immigration dataset: 3096313\n"
     ]
    }
   ],
   "source": [
    "# count the total number of records\n",
    "total_immigration_row = immigration_df.count()\n",
    "print('Total number of row of immigration dataset: {}'.format(total_immigration_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets see the dataframe schema\n",
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_nan_count_df = immigration_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in immigration_df.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_nan_count_df = pd.melt(immigration_nan_count_df, var_name='cols', value_name='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values summary:\n",
      "         cols   values  % missing values\n",
      "0      cicid        0          0.000000\n",
      "1      i94yr        0          0.000000\n",
      "2     i94mon        0          0.000000\n",
      "3     i94cit        0          0.000000\n",
      "4     i94res        0          0.000000\n",
      "5    i94port        0          0.000000\n",
      "6    arrdate        0          0.000000\n",
      "7    i94mode      239          0.007719\n",
      "8    i94addr   152592          4.928184\n",
      "9    depdate   142457          4.600859\n",
      "10    i94bir      802          0.025902\n",
      "11   i94visa        0          0.000000\n",
      "12     count        0          0.000000\n",
      "13  dtadfile        1          0.000032\n",
      "14  visapost  1881250         60.757746\n",
      "15     occup  3088187         99.737559\n",
      "16   entdepa      238          0.007687\n",
      "17   entdepd   138429          4.470769\n",
      "18   entdepu  3095921         99.987340\n",
      "19   matflag   138429          4.470769\n",
      "20   biryear      802          0.025902\n",
      "21   dtaddto      477          0.015405\n",
      "22    gender   414269         13.379429\n",
      "23    insnum  2982605         96.327632\n",
      "24   airline    83627          2.700857\n",
      "25    admnum        0          0.000000\n",
      "26     fltno    19549          0.631364\n",
      "27  visatype        0          0.000000\n"
     ]
    }
   ],
   "source": [
    "immigration_nan_count_df['% missing values'] = 100*immigration_nan_count_df['values']/total_immigration_row\n",
    "print('Missing values summary:\\n {}'.format(immigration_nan_count_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We see that there is 4 columns with such a high missing values percentages: `visapost`, `occup`, `entdepu`, `insnum`.\n",
    "We will remove these columns from immigration data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cols = ['occup', 'entdepu','insnum', 'visapost']\n",
    "\n",
    "# drop these columns\n",
    "immigration_df = immigration_df.drop(*cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We also remove rows that have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "immigration_df=immigration_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of immigration data table after remove missing data: 2384498\n"
     ]
    }
   ],
   "source": [
    "print('Length of immigration data table after remove missing data: {}'.format(immigration_df.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Immigration Schema: \n",
      "\n",
      "root\n",
      " |-- cicid: double (nullable = true)\n",
      " |-- i94yr: double (nullable = true)\n",
      " |-- i94mon: double (nullable = true)\n",
      " |-- i94cit: double (nullable = true)\n",
      " |-- i94res: double (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: double (nullable = true)\n",
      " |-- i94mode: double (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: double (nullable = true)\n",
      " |-- i94bir: double (nullable = true)\n",
      " |-- i94visa: double (nullable = true)\n",
      " |-- count: double (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: double (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the new schema for i94 immigration\n",
    "print('Immigration Schema: \\n')\n",
    "immigration_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We also want to make sure that there is no duplicate value in `cicid` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of immigration data table after remove duplicate cicid: 2384498\n"
     ]
    }
   ],
   "source": [
    "immigration_df = immigration_df.dropDuplicates(['cicid'])\n",
    "print('Length of immigration data table after remove duplicate cicid: {}'.format(immigration_df.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **World Temperature Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df = spark.read.csv('../../data2/GlobalLandTemperaturesByCity.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|                 dt|AverageTemperature|AverageTemperatureUncertainty| City|Country|Latitude|Longitude|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|             6.068|           1.7369999999999999|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1743-12-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-01-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-02-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "|1744-03-01 00:00:00|              null|                         null|Århus|Denmark|  57.05N|   10.33E|\n",
      "+-------------------+------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display the first five records\n",
    "temperature_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8599212\n"
     ]
    }
   ],
   "source": [
    "# check the total number of records\n",
    "temperature_total_row = temperature_df.count()\n",
    "print(temperature_total_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dt: timestamp (nullable = true)\n",
      " |-- AverageTemperature: double (nullable = true)\n",
      " |-- AverageTemperatureUncertainty: double (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print dataframe schema\n",
    "temperature_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Cast `dt` colums to string to summary for missing values, we will create a new dataframe for this purpose of missing values summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df_2 = temperature_df.withColumn(\"dt\",col(\"dt\").cast(StringType())) # convert dt column type to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temp_nan_count_df = temperature_df_2.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in temperature_df_2.columns]).toPandas()\n",
    "temp_nan_count_df = pd.melt(temp_nan_count_df, var_name='cols', value_name='values')\n",
    "temp_nan_count_df['% missing values'] = 100*temp_nan_count_df['values']/temperature_total_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Summary for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            cols  values  % missing values\n",
      "0                             dt       0          0.000000\n",
      "1             AverageTemperature  364130          4.234458\n",
      "2  AverageTemperatureUncertainty  364130          4.234458\n",
      "3                           City       0          0.000000\n",
      "4                        Country       0          0.000000\n",
      "5                       Latitude       0          0.000000\n",
      "6                      Longitude       0          0.000000\n"
     ]
    }
   ],
   "source": [
    "print(temp_nan_count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Drop missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df = temperature_df.dropna(subset=['AverageTemperature', 'AverageTemperatureUncertainty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8235082\n"
     ]
    }
   ],
   "source": [
    "print(temperature_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Drop duplicates rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "temperature_df = temperature_df.drop_duplicates(subset=['dt', 'City', 'Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8190783\n"
     ]
    }
   ],
   "source": [
    "print(temperature_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### **U.S. City Demographic Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics_df = spark.read.csv('us-cities-demographics.csv', inferSchema=True, header=True, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8            40601   \n",
       "1            Quincy  Massachusetts        41.0            44129   \n",
       "2            Hoover        Alabama        38.5            38040   \n",
       "3  Rancho Cucamonga     California        34.5            88127   \n",
       "4            Newark     New Jersey        34.6           138040   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              41862             82463                1562         30908   \n",
       "1              49500             93629                4147         32935   \n",
       "2              46799             84839                4819          8229   \n",
       "3              87105            175232                5821         33878   \n",
       "4             143873            281913                5829         86253   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first five records\n",
    "demographics_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: double (nullable = true)\n",
      " |-- Male Population: integer (nullable = true)\n",
      " |-- Female Population: integer (nullable = true)\n",
      " |-- Total Population: integer (nullable = true)\n",
      " |-- Number of Veterans: integer (nullable = true)\n",
      " |-- Foreign-born: integer (nullable = true)\n",
      " |-- Average Household Size: double (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lets see the dataframe schema\n",
    "demographics_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2891\n"
     ]
    }
   ],
   "source": [
    "# count the number of records in dataset\n",
    "total_demographics_row = demographics_df.count()\n",
    "print(total_demographics_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demo_nan_count_df = demographics_df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in demographics_df.columns]).toPandas()\n",
    "demo_nan_count_df = pd.melt(demo_nan_count_df, var_name='cols', value_name='values')\n",
    "demo_nan_count_df['% missing values'] = 100*demo_nan_count_df['values']/demographics_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Summary missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      cols  values  % missing values\n",
      "0                     City       0          0.000000\n",
      "1                    State       0          0.000000\n",
      "2               Median Age       0          0.000000\n",
      "3          Male Population       3          0.103770\n",
      "4        Female Population       3          0.103770\n",
      "5         Total Population       0          0.000000\n",
      "6       Number of Veterans      13          0.449671\n",
      "7             Foreign-born      13          0.449671\n",
      "8   Average Household Size      16          0.553442\n",
      "9               State Code       0          0.000000\n",
      "10                    Race       0          0.000000\n",
      "11                   Count       0          0.000000\n"
     ]
    }
   ],
   "source": [
    "print(demo_nan_count_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Remove rows have missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2875\n"
     ]
    }
   ],
   "source": [
    "print(demographics_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics_df = demographics_df.dropDuplicates(subset=['City', 'State', 'State Code', 'Race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2875\n"
     ]
    }
   ],
   "source": [
    "print(demographics_df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The conceptual data model is as image below.\n",
    "We have 1 fact table as `i94immigration_fact` and 3 dimension table as `country_temperature_dim`, `calendar_dim` and `us_demographics_dim`.\n",
    "These dimension tables can link to fact table through `i94res`, `arrdate` and `i94addr` fields in `i94immigration_fact` table.\n",
    "With this database, data analysit can deep dive to figure out patterns for immigration data, such as there is any commonality between residence country and US country state - are they prefer some specific US states over other US state.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "![data_model](data_model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data pipelines steps are as below:\n",
    "- Load the datasets with Spark dataframe\n",
    "- Explore and clean immigration dataframe for each month\n",
    "- Explore and clean temperature dataframe\n",
    "- Explore and clean demographics dataframe\n",
    "- Create calendar table\n",
    "- Create temperature table\n",
    "- Create demographics table\n",
    "- Create immigration fact table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create calendar_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_calendar_dim(df):\n",
    "    \"\"\"\n",
    "    Function to create calendar_dim table\n",
    "    \n",
    "    :param df: spark immigration dataframe\n",
    "    :return: calendar_dim table\n",
    "    \"\"\"\n",
    "    # udf function to convert arrival date to datetime\n",
    "    epoch = dt.datetime(1960, 1, 1)\n",
    "    udf_datetime = udf(lambda x: (epoch.date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "    \n",
    "    # create calendar table\n",
    "    calendar_df = df.select(['arrdate']).withColumn(\"arrdate\", udf_datetime(df.arrdate)).distinct()\n",
    "    \n",
    "    # expand df by adding other calendar columns\n",
    "    calendar_df = calendar_df.withColumn('arrival_day', dayofmonth('arrdate'))\n",
    "    calendar_df = calendar_df.withColumn('arrival_week', weekofyear('arrdate'))\n",
    "    calendar_df = calendar_df.withColumn('arrival_month', month('arrdate'))\n",
    "    calendar_df = calendar_df.withColumn('arrival_year', year('arrdate'))\n",
    "    calendar_df = calendar_df.withColumn('arrival_weekday', dayofweek('arrdate'))\n",
    "\n",
    "    calendar_df = calendar_df.withColumn('id', monotonically_increasing_id())\n",
    "    \n",
    "    return calendar_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "calendar_dim = create_calendar_dim(immigration_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check top 5 rows of calendar_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arrdate</th>\n",
       "      <th>arrival_day</th>\n",
       "      <th>arrival_week</th>\n",
       "      <th>arrival_month</th>\n",
       "      <th>arrival_year</th>\n",
       "      <th>arrival_weekday</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>8589934592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>6</td>\n",
       "      <td>25769803776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-18</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>42949672960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-09</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>7</td>\n",
       "      <td>68719476736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-11</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>85899345920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      arrdate  arrival_day  arrival_week  arrival_month  arrival_year  \\\n",
       "0  2016-04-22           22            16              4          2016   \n",
       "1  2016-04-15           15            15              4          2016   \n",
       "2  2016-04-18           18            16              4          2016   \n",
       "3  2016-04-09            9            14              4          2016   \n",
       "4  2016-04-11           11            15              4          2016   \n",
       "\n",
       "   arrival_weekday           id  \n",
       "0                6   8589934592  \n",
       "1                6  25769803776  \n",
       "2                2  42949672960  \n",
       "3                7  68719476736  \n",
       "4                2  85899345920  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create country_temperature_dim table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We created a new file named `i94res.csv` which extracted data from `I94_SAS_Labels_Descriptions.SAS` to map country name with country code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_country_temperature_dim(immigration_df, temp_df):\n",
    "    \"\"\"\n",
    "    Function to create country_temperature_dim\n",
    "    \n",
    "    :param immigration_df: spark immigration dataframe\n",
    "    :param temp_df: spark global land temperature dataframe\n",
    "    :return: country_temperature_dim dimension table\n",
    "    \"\"\"\n",
    "    \n",
    "    # load the i94res to country mapping data\n",
    "    country_code_mapping = pd.read_csv('i94res.csv')\n",
    "    \n",
    "    land_temp_df = temp_df.select(['Country', 'AverageTemperature']).groupby('Country').avg()\n",
    "    land_temp_df = land_temp_df.withColumnRenamed('avg(AverageTemperature)', 'average_temperature') \\\n",
    "                                       .withColumnRenamed('Country', 'country').toPandas()\n",
    "    \n",
    "    @udf()\n",
    "    def get_country_average_temperature(country_name):\n",
    "        avg_temp = land_temp_df[land_temp_df['country']==country_name]['average_temperature']\n",
    "        \n",
    "        if not avg_temp.empty:\n",
    "            return str(avg_temp.iloc[0])\n",
    "    \n",
    "    @udf()\n",
    "    def get_country_name(country_code):\n",
    "        name = country_code_mapping[country_code_mapping['code']==country_code]['Name'].iloc[0]\n",
    "        \n",
    "        if name:\n",
    "            return name.title()\n",
    "\n",
    "    # select and rename i94res column\n",
    "    country_temperature_dim = immigration_df.select(['i94res']).distinct() \\\n",
    "                .withColumnRenamed('i94res', 'country_code')\n",
    "    \n",
    "    # create country_name column\n",
    "    country_temperature_dim = country_temperature_dim.withColumn('country_name', get_country_name(country_temperature_dim.country_code))\n",
    "    \n",
    "    # create average_temperature column\n",
    "    country_temperature_dim = country_temperature_dim.withColumn('average_temperature', get_country_average_temperature(country_temperature_dim.country_name))\n",
    "    \n",
    "    return country_temperature_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "country_temperature_dim = create_country_temperature_dim(immigration_df, temperature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-------------------+\n",
      "|country_code|country_name|average_temperature|\n",
      "+------------+------------+-------------------+\n",
      "|       692.0|     Ecuador|      20.5391705374|\n",
      "|       299.0|    Mongolia|     -3.36548531952|\n",
      "|       576.0| El Salvador|      25.2628525509|\n",
      "|       735.0|  Montenegro|      10.2210401137|\n",
      "|       206.0|   Hong Kong|      21.4236961538|\n",
      "+------------+------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country_temperature_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "print(country_temperature_dim.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create us_demographics_dim table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_us_demographics_dim(df):\n",
    "    \"\"\"\n",
    "    Function to create us_demographics_dim table\n",
    "\n",
    "    :param df: spark demographics dataframe\n",
    "    :return: us_demographics_dim table\n",
    "    \"\"\"\n",
    "    us_demographics_dim = df.withColumnRenamed('Median Age','median_age') \\\n",
    "            .withColumnRenamed('City', 'city') \\\n",
    "            .withColumnRenamed('State', 'state') \\\n",
    "            .withColumnRenamed('Male Population', 'male_population') \\\n",
    "            .withColumnRenamed('Female Population', 'female_population') \\\n",
    "            .withColumnRenamed('Total Population', 'total_population') \\\n",
    "            .withColumnRenamed('Number of Veterans', 'number_of_veterans') \\\n",
    "            .withColumnRenamed('Foreign-born', 'foreign_born') \\\n",
    "            .withColumnRenamed('Average Household Size', 'average_household_size') \\\n",
    "            .withColumnRenamed('State Code', 'state_code') \\\n",
    "            .withColumnRenamed('Race', 'race') \\\n",
    "            .withColumnRenamed('Count', 'count')\n",
    "\n",
    "    # lets add an id column\n",
    "    us_demographics_dim = us_demographics_dim.withColumn('id', monotonically_increasing_id())\n",
    "    \n",
    "    return us_demographics_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "us_demographics_dim = create_us_demographics_dim(demographics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Check top 5 rows of us_demographics_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>median_age</th>\n",
       "      <th>male_population</th>\n",
       "      <th>female_population</th>\n",
       "      <th>total_population</th>\n",
       "      <th>number_of_veterans</th>\n",
       "      <th>foreign_born</th>\n",
       "      <th>average_household_size</th>\n",
       "      <th>state_code</th>\n",
       "      <th>race</th>\n",
       "      <th>count</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wilmington</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>52346</td>\n",
       "      <td>63601</td>\n",
       "      <td>115947</td>\n",
       "      <td>5908</td>\n",
       "      <td>7401</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>3152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tampa</td>\n",
       "      <td>Florida</td>\n",
       "      <td>35.3</td>\n",
       "      <td>175517</td>\n",
       "      <td>193511</td>\n",
       "      <td>369028</td>\n",
       "      <td>20636</td>\n",
       "      <td>58795</td>\n",
       "      <td>2.47</td>\n",
       "      <td>FL</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>95154</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gastonia</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>36.9</td>\n",
       "      <td>35527</td>\n",
       "      <td>39023</td>\n",
       "      <td>74550</td>\n",
       "      <td>3537</td>\n",
       "      <td>5715</td>\n",
       "      <td>2.67</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2788</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tyler</td>\n",
       "      <td>Texas</td>\n",
       "      <td>33.9</td>\n",
       "      <td>50422</td>\n",
       "      <td>53283</td>\n",
       "      <td>103705</td>\n",
       "      <td>4813</td>\n",
       "      <td>8225</td>\n",
       "      <td>2.59</td>\n",
       "      <td>TX</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1057</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city           state  median_age  male_population  female_population  \\\n",
       "0      Quincy   Massachusetts        41.0            44129              49500   \n",
       "1  Wilmington  North Carolina        35.5            52346              63601   \n",
       "2       Tampa         Florida        35.3           175517             193511   \n",
       "3    Gastonia  North Carolina        36.9            35527              39023   \n",
       "4       Tyler           Texas        33.9            50422              53283   \n",
       "\n",
       "   total_population  number_of_veterans  foreign_born  average_household_size  \\\n",
       "0             93629                4147         32935                    2.39   \n",
       "1            115947                5908          7401                    2.24   \n",
       "2            369028               20636         58795                    2.47   \n",
       "3             74550                3537          5715                    2.67   \n",
       "4            103705                4813          8225                    2.59   \n",
       "\n",
       "  state_code                               race  count  id  \n",
       "0         MA                              White  58723   0  \n",
       "1         NC                              Asian   3152   1  \n",
       "2         FL                 Hispanic or Latino  95154   2  \n",
       "3         NC                              Asian   2788   3  \n",
       "4         TX  American Indian and Alaska Native   1057   4  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_demographics_dim.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2875\n"
     ]
    }
   ],
   "source": [
    "print(us_demographics_dim.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create i94immigration_fact table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_i94immigration_fact(df):\n",
    "    \"\"\"\n",
    "    Function to create i94 immigration fact\n",
    "    \n",
    "    :param df: spark immigration dataframe\n",
    "    :return: i94immigration_fact table\n",
    "    \"\"\"\n",
    "\n",
    "    # udf function to convert arrival date to datetime\n",
    "    epoch = dt.datetime(1960, 1, 1)\n",
    "    udf_datetime = udf(lambda x: (epoch.date() + dt.timedelta(x)).isoformat() if x else None)\n",
    "    \n",
    "    # create i94immigration_fact\n",
    "    i94immigration_fact = df.select(\"cicid\", \"i94res\", \"i94port\", \"arrdate\", \"i94mode\", \"i94addr\", \"depdate\", \"i94bir\",\n",
    "                      \"count\", \"entdepa\", \"entdepd\", \"biryear\", \"dtaddto\", \"gender\")\n",
    "    \n",
    "    # convert arrival date to datetime\n",
    "    i94immigration_fact = i94immigration_fact.withColumn(\"arrdate\", udf_datetime(i94immigration_fact.arrdate))\n",
    "    \n",
    "    return i94immigration_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94immigration_fact = create_i94immigration_fact(immigration_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>i94bir</th>\n",
       "      <th>count</th>\n",
       "      <th>entdepa</th>\n",
       "      <th>entdepd</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>SFR</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>1974.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>596.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>NAS</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>20547.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>934.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20549.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1051.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NEW</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>06292016</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2734.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>SAJ</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>PR</td>\n",
       "      <td>20552.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cicid  i94res i94port     arrdate  i94mode i94addr  depdate  i94bir  \\\n",
       "0   558.0   103.0     SFR  2016-04-01      1.0      CA  20547.0    42.0   \n",
       "1   596.0   103.0     NAS  2016-04-01      1.0      FL  20547.0    24.0   \n",
       "2   934.0   104.0     NEW  2016-04-01      1.0      NY  20549.0    54.0   \n",
       "3  1051.0   104.0     NEW  2016-04-01      1.0      NY  20551.0    28.0   \n",
       "4  2734.0   107.0     SAJ  2016-04-01      1.0      PR  20552.0     6.0   \n",
       "\n",
       "   count entdepa entdepd  biryear   dtaddto gender  \n",
       "0    1.0       G       O   1974.0  06292016      M  \n",
       "1    1.0       G       N   1992.0  06292016      M  \n",
       "2    1.0       G       O   1962.0  06292016      F  \n",
       "3    1.0       G       O   1988.0  06292016      M  \n",
       "4    1.0       G       O   2010.0  09302016      M  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i94immigration_fact.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2384498\n"
     ]
    }
   ],
   "source": [
    "print(i94immigration_fact.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_no_empty_record(df_name, df):\n",
    "    \"\"\"\n",
    "    Method to check if a data table got empty record\n",
    "    :param df_name: name of data table\n",
    "    :param df: datatable\n",
    "    :return: print out pass/fail check result\n",
    "    \"\"\"\n",
    "    total_count = df.count()\n",
    "    if total_count == 0:\n",
    "        print('Data quality checks failed (empty record) for table: {}'.format(df_name))\n",
    "    else:\n",
    "        print('Data quality checks passed (no empty record) for table: {}'.format(df_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def check_no_duplicate_id(df_name, df, unique_id):\n",
    "    \"\"\"\n",
    "    Method to check if unique id of a table got duplicate.\n",
    "    :param df_name: name of data table\n",
    "    :param df: datatable\n",
    "    :unique_id: column name of unique id of a table\n",
    "    :return: print out pass/fail result check result\n",
    "    \"\"\"\n",
    "    if df.count() == df.dropDuplicates([unique_id]).count():\n",
    "        print('Data quality checks passed (no duplicate id) for table: {}'.format(df_name))\n",
    "    else:\n",
    "        print('Data quality checks failed (duplicate id) for table: {}'.format(df_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data quality checks passed (no empty record) for table: i94immigration_fact\n",
      "Data quality checks passed (no duplicate id) for table: i94immigration_fact\n",
      "Data quality checks passed (no empty record) for table: calendar_dim\n",
      "Data quality checks passed (no duplicate id) for table: calendar_dim\n",
      "Data quality checks passed (no empty record) for table: usa_demographics_dim\n",
      "Data quality checks passed (no duplicate id) for table: usa_demographics_dim\n",
      "Data quality checks passed (no empty record) for table: country_temperature_dim\n",
      "Data quality checks passed (no duplicate id) for table: country_temperature_dim\n"
     ]
    }
   ],
   "source": [
    "tables = {\n",
    "    'i94immigration_fact': [i94immigration_fact, 'cicid'],\n",
    "    'calendar_dim': [calendar_dim, 'id'],\n",
    "    'usa_demographics_dim': [us_demographics_dim, 'id'],\n",
    "    'country_temperature_dim': [country_temperature_dim, 'country_code']\n",
    "}\n",
    "\n",
    "for df_name, df_id_list in tables.items():\n",
    "    check_no_empty_record(df_name, df_id_list[0])\n",
    "    check_no_duplicate_id(df_name, df_id_list[0], df_id_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Testing - Query the data model\n",
    "In order to make sure that we already have the final data model, we will run a query to check.\n",
    "It might be interesting to see if immigrants would generally flock to states with generally more immigrants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|i94addr| count|\n",
      "+-------+------+\n",
      "|     FL|515286|\n",
      "|     NY|456061|\n",
      "|     CA|388254|\n",
      "|     HI|135723|\n",
      "|     TX|105597|\n",
      "+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create table to count immigrants by arrival states\n",
    "top_states_df = i94immigration_fact.groupBy(\"i94addr\").count()\n",
    "top_states_df = top_states_df.orderBy('count', ascending=False)\n",
    "top_states_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Now we will join `top_states_df` with `us_demographics_dim` to map top states with state name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+----------+\n",
      "|i94addr| count|     state|\n",
      "+-------+------+----------+\n",
      "|     FL|515286|   Florida|\n",
      "|     NY|456061|  New York|\n",
      "|     CA|388254|California|\n",
      "|     HI|135723|    Hawaii|\n",
      "|     TX|105597|     Texas|\n",
      "+-------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_states_df = top_states_df.alias('df1')\n",
    "us_demographics_dim = us_demographics_dim.alias('df2')\n",
    "top_states_df = top_states_df.join(us_demographics_dim, top_states_df.i94addr==us_demographics_dim.state_code).select(\n",
    "    'df1.*', 'df2.state').distinct()\n",
    "top_states_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "We have the results for the name of top 5 arrival states for immigrants: `Florida`, `New York`, `California`, `Hawaii` and `Texas`.\n",
    "Now we want to find top 5 states which have the highest number of foreign born."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|     state|sum(foreign_born)|\n",
      "+----------+-----------------+\n",
      "|California|          7448257|\n",
      "|  New York|          3438081|\n",
      "|     Texas|          2942164|\n",
      "|   Florida|          1684897|\n",
      "|  Illinois|           941735|\n",
      "+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_foreign_born_cities = us_demographics_dim.select('city', 'state_code', 'state', 'foreign_born').orderBy('foreign_born', ascending=False).distinct()\n",
    "top_foreign_born_states = top_foreign_born_cities.select(\"state\", \"foreign_born\")\n",
    "top_foreign_born_states = top_foreign_born_states.groupBy(\"state\").sum().orderBy(\"sum(foreign_born)\", ascending=False)\n",
    "top_foreign_born_states.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "From the result above, we can see that 4/5 top arrival places for immigrants are actually in top 5 of having highest number of foreign born. \n",
    "They are: `California`, `New York`, `Texas` and `Florida`. From this first query, we can see that there is a correlation between immigrants arrival states and the quantity of foreign born in these states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### i94immigration_fact"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Feature \t| Description                                           \t|\n",
    "|---------\t|-------------------------------------------------------\t|\n",
    "| cicid   \t| unique id record                                      \t|\n",
    "| i94res  \t| resident country code                                 \t|\n",
    "| i94port \t| port of entry                                         \t|\n",
    "| arrdate \t| arrival date                                          \t|\n",
    "| i94mode \t| type of transportation                                \t|\n",
    "| i94addr \t| entry state                                           \t|\n",
    "| depdate \t| departure date                                        \t|\n",
    "| i94bir  \t| Age of Respondent in Years                            \t|\n",
    "| count   \t| Used for summary statistics                           \t|\n",
    "| entdepa \t| Arrival Flag - admitted or paroled into the U.S.      \t|\n",
    "| entdepd \t| Departure Flag - Departed, lost I-94 or is deceased   \t|\n",
    "| biryear \t| 4 digit year of birth                                 \t|\n",
    "| dtaddto \t| Character Date Field - Date to which admitted to U.S. \t|\n",
    "| gender  \t| Non-immigrant sex                                     \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### country_temperature_dim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Feature             \t| Description                        \t|\n",
    "|---------------------\t|------------------------------------\t|\n",
    "| country_code        \t| country code                       \t|\n",
    "| country_name        \t| country name                       \t|\n",
    "| average_temperature \t| average temperature of the country \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### calendar_dim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "| Feature         \t| Calendar            \t|\n",
    "|-----------------\t|---------------------\t|\n",
    "| id              \t| unique id of record \t|\n",
    "| arrdate         \t| arrival date        \t|\n",
    "| arrival_year    \t| year of arrival     \t|\n",
    "| arrival_month   \t| month of arrival    \t|\n",
    "| arrival_day     \t| day of arrival      \t|\n",
    "| arrival_week    \t| week of arrival     \t|\n",
    "| arrival_weekday \t| weekday of arrival  \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### us_demographics_dim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "editable": true
   },
   "source": [
    "| id                     \t| unique id of record                     \t|\n",
    "|------------------------\t|-----------------------------------------\t|\n",
    "| state_code             \t| code of state                           \t|\n",
    "| city                   \t| city name                               \t|\n",
    "| state                  \t| state name                              \t|\n",
    "| male_population        \t| total number of male population         \t|\n",
    "| female_population      \t| total number of female population       \t|\n",
    "| total_population       \t| total population                        \t|\n",
    "| number_of_veterans     \t| number of veterans                      \t|\n",
    "| foreign_born           \t| number of foreign born                  \t|\n",
    "| average_household_size \t| avarage size of household               \t|\n",
    "| race                   \t| respondent race                         \t|\n",
    "| count                  \t| total number of people of dominant race \t|\n",
    "| median_age             \t| median age of population                \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "    - This project uses Apache Spark as it is the right choice to handle big datasets.\n",
    "* Propose how often the data should be updated and why.\n",
    "    - The data should be updated monthly as we will have new dataset for every month.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "     - Currently we just using Spark in local mode, if the data increased by 100x - moving the Spark processing to Amazon EMR will be an optimal choice as it supports scaling.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "     - We can apply Apache Airflow to handle schedule update.\n",
    " * The database needed to be accessed by 100+ people.\n",
    "     - We can move our analytics database to Amazon Redshift which support scaling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
